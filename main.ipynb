{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z5ZMZrHbvTH"
      },
      "source": [
        "## Data loading and tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXyoc5dtwdQM",
        "outputId": "62f7b455-4660-4726-f58b-9744b3dbc37f"
      },
      "outputs": [],
      "source": [
        "#!wget https://raw.githubusercontent.com/nMaax/danteGPT/main/divina_commedia.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kSRe8AC0s55I"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "with open('divina_commedia.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNnBfFh9s-ML",
        "outputId": "bf969ac7-3223-424f-80ed-39656f8565b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFERNO CANTO 1\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura\n",
            "ché la diritta via era smarrita.\n",
            "Ahi quanto a dir qual era è cosa dura\n",
            "esta selva selvaggia e aspra e forte\n",
            "che nel pensier rinova la paura!\n",
            "Tant' è amara che poco è più morte;\n",
            "ma per trattar del ben ch'i' vi trovai,\n",
            "dirò de l'altre cose ch'i' v'ho scorte.\n",
            "Io non so ben ridir com' i' v'intrai,\n",
            "tant' era pien di sonno a quel punto\n",
            "che la verace via abbandonai.\n",
            "Ma poi ch'i' fui al piè d'un colle giunto,\n",
            "là dove terminava quel\n"
          ]
        }
      ],
      "source": [
        "print(text[:512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NWvA8bLa-LU7"
      },
      "outputs": [],
      "source": [
        "from tokenizer import RegexTokenizer\n",
        "\n",
        "tokenizer_training_size = len(text) // 4\n",
        "vocab_size = 500\n",
        "\n",
        "Dantokenizer = RegexTokenizer()\n",
        "Dantokenizer.train(text[:tokenizer_training_size], vocab_size=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CslBsRgs-BlX"
      },
      "outputs": [],
      "source": [
        "encode = Dantokenizer.encode\n",
        "decode = Dantokenizer.decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0GmeEENuyhK",
        "outputId": "ead1e315-73fa-42b3-97eb-eece5f6b3088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nel mezzo del cammin di nostra vita, mi ritrovai in una selva oscura.\n"
          ]
        }
      ],
      "source": [
        "print(decode(encode('Nel mezzo del cammin di nostra vita, mi ritrovai in una selva oscura.')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UiF4zFRbpH6"
      },
      "source": [
        "## Baseline, Transformer-free model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "edAktZYGw1NX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available. Training on: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU availability and move model and data\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available. Training on:\", device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available. Training on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zklkoveE3pOU"
      },
      "outputs": [],
      "source": [
        "from baseline import naiveLM\n",
        "\n",
        "naiveDante = naiveLM(vocab_size=vocab_size, latent_space_dim=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEe24la9_Z2w",
        "outputId": "36623a9d-abc5-4bab-c469-6dc16334f3c9"
      },
      "outputs": [],
      "source": [
        "def novel_generate(model, size=500, device=None):\n",
        "  if device is None:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use CUDA if available\n",
        "  return decode(model.generate(tokens=torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=size)[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current loss: 6.2388\n",
            "\n",
            "Corresponding text generation:\n",
            "\n",
            " \u0000�\u000farqusc� lees�tor����ttaطi� comk�wom� p� pu� com; la�ce no sp lui�]�anto�@�f0 disgn'anqu fulatratre#$ givitrogno quelW�I�en v un�\u0019�aiv con� al8ura���chiB\u0002\u0007z-�� du�on�ciàtti�,\n",
            "\u0013ssaratroB cosàdo\u0010� tu lo\n",
            "ose\u0013�\u0007< u par�ri�� penteM' el�spun�\u0013J sanò�òWvimo ma,\n",
            "&J cor�iâ pusogu� lui\u0007\u0001zial_� qu vi s o���er'un�Z sianto�<<P� sandoleYnettq� ques\u0003 quesnereI\u0017�ìme6 i tetiin << bsessa là��di tra! iltro�ià��2�tre�gl� cKR ne me cotti�I�|ran2 pu era noes�scranentiâ\u0018\u0015me(�sos vesta tu�micor do�\u0000 sa.\n",
            "ohhderce�1 ver��non re�ò\u000f ci�mela luitre ri pive disunal�sse fi ver�na\u0007ssaga� paiù\u0005sseV p>>.\n",
            " poiai<<B�* vi���.\n",
            "f foziggco!A puh oè�4YK\u0000ei�'ansosì�arWtor fi�mmo mon�ol Cs fora un\u000f� fores�� soA�òunura san pme��on�y ci al lo��quggraconcchido? o%2staI/tto���\u0006 cos elfrichi����\u001dperià� noi�Qu cofc�~\u0005<di pag� sol�% daG/! pri� ti seli8�� lor io: pa�m���se iso puomearx citor è du�\u0006ando�_ piùtovcon peror3 dosscchitt nonoer\u0016� pu'unri�\u0005z pQ quelV\n"
          ]
        }
      ],
      "source": [
        "from utils import get_batch\n",
        "xb, yb = get_batch(train_data)\n",
        "loss = naiveDante.compute_loss(xb, yb)\n",
        "print(f\"Current loss: {loss.item():.4f}\\n\")\n",
        "print(\"Corresponding text generation:\\n\\n\", novel_generate(model=naiveDante, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Train Loss = 6.2386, Test Loss = 6.2328\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(naiveDante\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaiveDante\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/danteGPT/utils/trainer.py:16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, test_data, optimizer, epochs, eval_every, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m test_loss_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m   xb, yb \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m   loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(xb, yb)\n\u001b[1;32m     18\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Projects/danteGPT/utils/DataLoader.py:10\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(data, batch_size, block_size, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#data = train_data if split == 'train' else test_data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m block_size), size\u001b[38;5;241m=\u001b[39m(batch_size,), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:i \u001b[38;5;241m+\u001b[39m block_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#y = torch.clamp(y, 0, vocab_size - 1)\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from utils import train_model\n",
        "\n",
        "optimizer = torch.optim.AdamW(naiveDante.parameters(), lr=1e-3)\n",
        "epochs = 10000\n",
        "\n",
        "train_model(model=naiveDante, train_data=train_data, test_data=test_data, optimizer=optimizer, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noz-MDcYS00r",
        "outputId": "6a4f9e4b-80f9-447e-d39b-dcecc65f91b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u0000ta stravi nal me m'a\n",
            "sola le molse\n",
            "chalia diomo aperché qua vemo, amcichio chi' i Comr comri gandaseggiamante, che perguenna pio, i'endo appenti da, <<Ooma,\n",
            "felle visotri vanto;\n",
            "ché risser' e sua piaroi divi.\n",
            "O occhi ognoress un corsquorave condressi>>,\n",
            "e gran questa e di vaciuinse là parco>>.\n",
            "Pio.\n",
            "Lo mala,\n",
            "di r 'l dege c' io lanotavigliace avolol de la lar e 'n priesserego non pu amolvitoonia, si poco li o me fossa darzionde ettei per gi' io>>.\n",
            "Suceiresi amone fe d'altro\n",
            "etta.\n",
            "Moi lui pian dicassa na piardo dar lorì occhi aspto,, ettreztizirto, al tro in e que haga da face aspchiar sogni accente spascatra a lui parole,\n",
            "a labbi mi rivisi;\n",
            "e\n",
            "E cia ch'inco ch'io rati;\n",
            "ne a uscue essentro vanno abborte l'i' ciò e contamma 'llli per con riml e lui doggio, e pa 'l per paare esserraciò la che tu me.\n",
            "Nare>>,\n",
            "chenravi 'nadi di suziamosuore l'alsc'in contiruti, mi sui\n",
            "l e tu la calte, e l', e, tu tutti fun maduFé fasca fho ci chiosta.\n",
            "se quella, nolto in mezzia\n",
            "do e lor Tond gire, <<izio ha riO dia; e pose algiun pi\n"
          ]
        }
      ],
      "source": [
        "print(novel_generate(model=naiveDante, device=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2OVQCQfcsBE"
      },
      "source": [
        "## Transformer based (self attention) implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dante import DanteLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i7Lx3l6Ge1Um"
      },
      "outputs": [],
      "source": [
        "Dante = DanteLM(vocab_size=vocab_size, context_window=256, latent_space_dim=128, num_heads=8, n_blocks=8, dropout_rate=0.0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPnRGs5hgDdX",
        "outputId": "92ad45dc-4a4b-431e-e047-018751a06879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u0000��sta��unti��za v�otre g eH�di�ychécavez^ssonos�\u000f� quel ma3\u0016�E le v��2àiògna�i� loos� delche? sì= col '� putti�)cV doo�omleK fa<<� a�uiݛ n��� 'sì�<an ch�L�'un� massol�ol'i\u0010& per fuui�glisso�� cagna� lor pider\fon��\u0016taWspW ques\u0004}�c/�\u000f'un�3� al_\u0012me t�\u0015 riscon s;\n",
            " so~tra� del il^� e� più:\n",
            "ticati\"\u0001�\\�de��gli&��dota no neV\u001e alN7 eragnareX�tro�tt colttiZ,\n",
            "� venmiredeun��, co� ch�\u0012are�:\n",
            " laoi v>\u001dppY mon���ome\"� ulo�ol]. i uco f mio  da se�gayalna par)tto<ce)e paVWhS�L chi� ri sp<�io fi siver�endob�ga noiir�\u001c\u0005m sì� quA�endo� mon C!;arecor�'a� luiRconh diru4ì�lo�za sìiùare�>> erado mppPre\u0001� non col�o� liA!,li p� vè no� suiò�m�b� elnon��Fos si� me'i là'alo� noi loreltraI miogn�o�i�-:\n",
            "are� lomelelo'ih de\u001b\u0003 pri\u0013\ftte\u0014 fi5 mi qusse�o\u001bU�ei\u0019tra so co\\moiùaiui comi�G� pi; neW���56\u0017�B di<Eda\u0004�inera�ca chi�f\"cc& san<<arver�\u0014\u0015)�\u0005��Bfٵ��tti fu��gicchi�U'i�� se miui5\n"
          ]
        }
      ],
      "source": [
        "print(novel_generate(model=Dante, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Train Loss = 4.0136, Test Loss = 3.9926\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(naiveDante\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_loss_values, test_loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaiveDante\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/danteGPT/utils/trainer.py:16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, test_data, optimizer, epochs, eval_every, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m test_loss_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m   xb, yb \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m   loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(xb, yb)\n\u001b[1;32m     18\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Projects/danteGPT/utils/DataLoader.py:11\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(data, batch_size, block_size, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m block_size), size\u001b[38;5;241m=\u001b[39m(batch_size,), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i:i \u001b[38;5;241m+\u001b[39m block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:i \u001b[38;5;241m+\u001b[39m block_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#y = torch.clamp(y, 0, vocab_size - 1)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
            "File \u001b[0;32m~/Projects/danteGPT/utils/DataLoader.py:11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m block_size), size\u001b[38;5;241m=\u001b[39m(batch_size,), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i:i \u001b[38;5;241m+\u001b[39m block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:i \u001b[38;5;241m+\u001b[39m block_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#y = torch.clamp(y, 0, vocab_size - 1)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from utils import train_model, plot_loss_functions\n",
        "\n",
        "optimizer = torch.optim.AdamW(naiveDante.parameters(), lr=1e-3)\n",
        "epochs = 10000\n",
        "\n",
        "train_loss_values, test_loss_values = train_model(model=naiveDante, train_data=train_data, test_data=test_data, optimizer=optimizer, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "bWdO8VkxGLho",
        "outputId": "dbb2fb2a-8b8c-4b8c-8c4a-eeab194e9b06"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_loss_values' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_loss_functions(\u001b[43mtrain_loss_values\u001b[49m, test_loss_values)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss_values' is not defined"
          ]
        }
      ],
      "source": [
        "plot_loss_functions(train_loss_values, test_loss_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHCdaIS4mTPs",
        "outputId": "9ac72d0e-f678-4972-c5d7-89814a1a4a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u0000iùqusodoce�� strechepcchie(- tu�\u0010enti daH� lo p èlo���< i�<��zettiM\u0003�ssa btrore��ché�'unxir ne���7ui� rita\u0002onoi�gn�\f<�+�� m'a���es�&ri com'un�non ts��G$ol m��6_ssaomere����~ a dmmoando]�a\u001cD4 con èHքF�+es�V�A'alH�% perna� fikff�ei com\\ versta fAorò�� ienterr�qesom�\\�{'al'Mcc� for setrauraQula del�gaP� do li <<iò par 'ura�ran.\n",
            "}t\u0001<<ssme�\u0004s>>.\n",
            "�hlڄlèsse gbb!� mionelo a è son� fa\u0003ffC� pardaru0�\u0002�\u0000in\t�~Tir sì pa veP fi se un�\f di.\n",
            "/� e�u gi&S�esW� nonbmoinQu mio non� 'Tar� u era diseN\u000eomegnai C nequ�eh\u0006�+�@Z;\n",
            " il5�in mioX� come cos'al�\u0013ol so\f quel\u0005�iù parCl*\u001d[`\u000fE\u0002\u0000na t)un uni�\fQu o� sì<el�2�\n",
            "� qu�\u000e tdiio:\n",
            " putronI&es'i�Aol fu����ʑ aб'Qu�\u000b t coser�6gimeiàome b~regna��ch> po vol\u000fò� dis&non5 <<cciaià comche�Ƌ{'i�\u0012� monffE�do\u001bruCtor�qu Cmo\"on du\u001esai�era� son�e �scendo9��ei� c co pu�=K)&`��tra, eè miI�are noniù�� cor Care gi��\n"
          ]
        }
      ],
      "source": [
        "print(decode(Dante.generate(tokens = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd9rt930wEBm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPCNV07hhci/rCvBoaDGSIj",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dante",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
