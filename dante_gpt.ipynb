{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z5ZMZrHbvTH"
      },
      "source": [
        "## Data loading and tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXyoc5dtwdQM",
        "outputId": "36d74ac5-df3d-4e0d-e065-f45e3af9de53"
      },
      "outputs": [],
      "source": [
        "# For any notebook\n",
        "!git clone https://github.com/nMaax/danteGPT\n",
        "!pip install -r danteGPT/requirements.txt\n",
        "\n",
        "import os\n",
        "os.chdir('danteGPT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6B-HzTlgWKQf"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Load the configuration from the YAML file\n",
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "tokenizer_training_size = config['model']['tokenizer_training_size']\n",
        "train_test_ratio = config['model']['train_test_ratio']\n",
        "vocab_size = config['model']['vocab_size']\n",
        "block_size = config['model']['block_size']\n",
        "batch_size = config['model']['batch_size']\n",
        "d_model = config['model']['d_model']\n",
        "num_heads = config['model']['num_heads']\n",
        "num_transformer_blocks = config['model']['num_transformer_blocks']\n",
        "ff_expansion_factor = config['model']['ff_expansion_factor']\n",
        "dropout_rate = config['model']['dropout_rate']\n",
        "device = 'cpu' # config['model']['device']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8F6ckNymEr2M"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "with open('divina_commedia.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7myIeTDEtPh",
        "outputId": "eb697635-1da0-46b6-9dbf-6b690981a087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFERNO CANTO 1\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura\n",
            "ché la diritta via era smarrita.\n",
            "Ahi quanto a dir qual era è cosa dura\n",
            "esta selva selvaggia e aspra e forte\n",
            "che nel pensier rinova la paura!\n",
            "Tant' è amara che poco è più morte;\n",
            "ma per trattar del ben ch'i' vi trovai,\n",
            "dirò de l'altre cose ch'i' v'ho scorte.\n",
            "Io non so ben ridir com' i' v'intrai,\n",
            "tant' era pien di sonno a quel punto\n",
            "che la verace via abbandonai.\n",
            "Ma poi ch'i' fui al piè d'un colle giunto,\n",
            "là dove terminava quel\n"
          ]
        }
      ],
      "source": [
        "print(text[:512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "47lyIS8yEufZ"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m tokenizer_training_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m*\u001b[39m tokenizer_training_size)\n\u001b[1;32m      5\u001b[0m Dantokenizer \u001b[38;5;241m=\u001b[39m RegexTokenizer()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mDantokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtokenizer_training_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/danteGPT/tokenizer/RegexTokenizer.py:21\u001b[0m, in \u001b[0;36mRegexTokenizer.train\u001b[0;34m(self, text, vocab_size, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# input text preprocessing\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tokenized_text \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks]\n\u001b[0;32m---> 21\u001b[0m _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrev_merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuous_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_merge\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/danteGPT/tokenizer/RegexTokenizer.py:35\u001b[0m, in \u001b[0;36mRegexTokenizer.continuous_merge\u001b[0;34m(self, tokenized_text, n_to_merge)\u001b[0m\n\u001b[1;32m     32\u001b[0m rev_merges \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m merge_iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_to_merge):\n\u001b[0;32m---> 35\u001b[0m     counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_bigrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m counter:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/danteGPT/tokenizer/RegexTokenizer.py:24\u001b[0m, in \u001b[0;36mRegexTokenizer.count_bigrams\u001b[0;34m(self, tokenized_text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_bigrams\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenized_text):\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbigram\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokenized_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbigram\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/dante/lib/python3.10/collections/__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 577\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/dante/lib/python3.10/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
            "File \u001b[0;32m~/Projects/danteGPT/tokenizer/RegexTokenizer.py:24\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_bigrams\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenized_text):\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m Counter(bigram \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokenized_text \u001b[38;5;28;01mfor\u001b[39;00m bigram \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tokenizer import RegexTokenizer\n",
        "\n",
        "tokenizer_training_size = int(len(text) * tokenizer_training_size)\n",
        "\n",
        "Dantokenizer = RegexTokenizer()\n",
        "Dantokenizer.train(text[:tokenizer_training_size], vocab_size=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pLm1LsQExCs"
      },
      "outputs": [],
      "source": [
        "encode = Dantokenizer.encode\n",
        "decode = Dantokenizer.decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wev2GbokE0dZ",
        "outputId": "99e2566d-69d5-4541-cc50-9e5f7b9bfb5a"
      },
      "outputs": [],
      "source": [
        "print(decode(encode('Nel mezzo del cammin di nostra vita, mi ritrovai in una selva oscura.')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJV9ctZzE3Us"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(train_test_ratio*len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIaguu0jFiFp",
        "outputId": "8be54e11-2710-49c2-de4b-7b41ca356c91"
      },
      "outputs": [],
      "source": [
        "# Check for GPU availability and move model and data\n",
        "if device == \"cpu\":\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Training on CPU.\")\n",
        "elif device == \"cuda\" and torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available. Training on:\", device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available. Training on CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgcsmogJFjo8"
      },
      "source": [
        "## Baseline, Transformer-free model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK_ZbzlrFo0A"
      },
      "outputs": [],
      "source": [
        "from baseline import DanteBaseline\n",
        "naiveDante = DanteBaseline(vocab_size=vocab_size, embedding_dim=d_model, context_window=block_size, ff_expansion_factor=ff_expansion_factor).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK983hjOFquI"
      },
      "outputs": [],
      "source": [
        "def novel_generate(model, size=500, device=None):\n",
        "  if device is None:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use CUDA if available\n",
        "  return decode(model.generate(context=torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=size)[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJ_VgKBFxR7",
        "outputId": "0e12bf43-2d93-4554-ec9d-b943b876120a"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  print(novel_generate(model=naiveDante, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qcDoP2kF0Qk",
        "outputId": "a1994011-bd57-4176-dfc9-34e6eb407a8b"
      },
      "outputs": [],
      "source": [
        "from utils import train_model, plot_loss_functions\n",
        "\n",
        "optimizer = torch.optim.AdamW(naiveDante.parameters(), lr=1e-3)\n",
        "epochs = 5 * 1000\n",
        "\n",
        "train_loss_values, test_loss_values = train_model(model=naiveDante, train_data=train_data, test_data=test_data, optimizer=optimizer, epochs=epochs, block_size=block_size, batch_size=batch_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "E-mKeAyqwGah",
        "outputId": "cc15c736-bebf-4f49-e879-88418b80f5a7"
      },
      "outputs": [],
      "source": [
        "plot_loss_functions(train_loss_values, test_loss_values, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4f_DPg4F2GW",
        "outputId": "9a5b540c-e414-4ae3-957b-daf5fe3e8947"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  print(novel_generate(model=naiveDante, size=500, device=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvkngGCfF44s"
      },
      "source": [
        "## Transformer based (self attention) implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_p3QDuTIHe6"
      },
      "outputs": [],
      "source": [
        "from dante import DanteTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me0aOCVhF5OW"
      },
      "outputs": [],
      "source": [
        "Dante = DanteTransformer(vocab_size=vocab_size, block_size=block_size, d_model=d_model, num_heads=num_heads, num_transformer_blocks=num_transformer_blocks, ff_expansion_factor=ff_expansion_factor, dropout_rate=dropout_rate).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCE0J5gF7ef",
        "outputId": "519caa64-74cd-4c23-9a2f-31aecbeeff4f"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  print(novel_generate(model=Dante, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "collapsed": true,
        "id": "MVP9aPoDF8vg",
        "outputId": "2239cf0b-15e7-4c56-ce22-673ebc637e6d"
      },
      "outputs": [],
      "source": [
        "from utils import train_model, plot_loss_functions\n",
        "\n",
        "optimizer = torch.optim.AdamW(Dante.parameters(), lr=1e-3)\n",
        "epochs = 10 * 1000\n",
        "\n",
        "train_loss_values, test_loss_values = train_model(model=Dante, train_data=train_data, test_data=test_data, optimizer=optimizer, epochs=epochs, batch_size=batch_size, block_size=block_size, eval_every=1000, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "collapsed": true,
        "id": "JIefYokfF-Lk",
        "outputId": "defde3e5-8cb8-44f6-bdd4-ccffe171decc"
      },
      "outputs": [],
      "source": [
        "plot_loss_functions(train_loss_values, test_loss_values, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZIbPTkJF_ZB",
        "outputId": "f7cf8767-1ea4-452a-e472-97dac612dd7e"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  print(novel_generate(model=Dante, size=500, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcZ8DPKjIORv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dante",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
