{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNVBLUHu0jD9VrWgU+0p9KX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nMaax/danteGPT/blob/main/dante_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/nMaax/danteGPT/main/divina_commedia.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXyoc5dtwdQM",
        "outputId": "7083bd77-427e-480d-80ea-1d355e22354e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-15 21:41:03--  https://raw.githubusercontent.com/nMaax/danteGPT/main/divina_commedia.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 448183 (438K) [text/plain]\n",
            "Saving to: ‘divina_commedia.txt.1’\n",
            "\n",
            "divina_commedia.txt 100%[===================>] 437.68K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-03-15 21:41:03 (102 MB/s) - ‘divina_commedia.txt.1’ saved [448183/448183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file\n",
        "with open('divina_commedia.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "kSRe8AC0s55I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:10000])"
      ],
      "metadata": {
        "id": "uNnBfFh9s-ML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3826d3-fd76-4b12-aa64-d9b9d4b88ced"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFERNO CANTO 1\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura\n",
            "ché la diritta via era smarrita.\n",
            "Ahi quanto a dir qual era è cosa dura\n",
            "esta selva selvaggia e aspra e forte\n",
            "che nel pensier rinova la paura!\n",
            "Tant’ è amara che poco è più morte;\n",
            "ma per trattar del ben ch’i’ vi trovai,\n",
            "dirò de l’altre cose ch’i’ v’ho scorte.\n",
            "Io non so ben ridir com’ i’ v’intrai,\n",
            "tant’ era pien di sonno a quel punto\n",
            "che la verace via abbandonai.\n",
            "Ma poi ch’i’ fui al piè d’un colle giunto,\n",
            "là dove terminava quella valle\n",
            "che m’avea di paura il cor compunto,\n",
            "guardai in alto, e vidi le sue spalle\n",
            "vestite già de’ raggi del pianeta\n",
            "che mena dritto altrui per ogne calle.\n",
            "Allor fu la paura un poco queta\n",
            "che nel lago del cor m’era durata\n",
            "la notte ch’i’ passai con tanta pieta.\n",
            "E come quei che con lena affannata\n",
            "uscito fuor del pelago a la riva\n",
            "si volge a l’acqua perigliosa e guata,\n",
            "così l’animo mio, ch’ancor fuggiva,\n",
            "si volse a retro a rimirar lo passo\n",
            "che non lasciò già mai persona viva.\n",
            "Poi ch’èi posato un poco il corpo lasso,\n",
            "ripresi via per la piaggia diserta,\n",
            "sì che ’l piè fermo sempre era ’l più basso.\n",
            "Ed ecco, quasi al cominciar de l’erta,\n",
            "una lonza leggera e presta molto,\n",
            "che di pel macolato era coverta;\n",
            "e non mi si partia dinanzi al volto,\n",
            "anzi ’mpediva tanto il mio cammino,\n",
            "ch’i’ fui per ritornar più volte vòlto.\n",
            "Temp’ era dal principio del mattino,\n",
            "e ’l sol montava ’n sù con quelle stelle\n",
            "ch’eran con lui quando l’amor divino\n",
            "mosse di prima quelle cose belle;\n",
            "sì ch’a bene sperar m’era cagione\n",
            "di quella fiera a la gaetta pelle\n",
            "l’ora del tempo e la dolce stagione;\n",
            "ma non sì che paura non mi desse\n",
            "la vista che m’apparve d’un leone.\n",
            "Questi parea che contra me venisse\n",
            "con la test’ alta e con rabbiosa fame,\n",
            "sì che parea che l’aere ne tremesse.\n",
            "Ed una lupa, che di tutte brame\n",
            "sembiava carca ne la sua magrezza,\n",
            "e molte genti fé già viver grame,\n",
            "questa mi porse tanto di gravezza\n",
            "con la paura ch’uscia di sua vista,\n",
            "ch’io perdei la speranza de l’altezza.\n",
            "E qual è quei che volontieri acquista,\n",
            "e giugne ’l tempo che perder lo face,\n",
            "che ’n tutti suoi pensier piange e s’attrista;\n",
            "tal mi fece la bestia sanza pace,\n",
            "che, venendomi ’ncontro, a poco a poco\n",
            "mi ripigneva là dove ’l sol tace.\n",
            "Mentre ch’i’ rovinava in basso loco,\n",
            "dinanzi a li occhi mi si fu offerto\n",
            "chi per lungo silenzio parea fioco.\n",
            "Quando vidi costui nel gran diserto,\n",
            "«\n",
            "«qual che tu sii, od ombra od omo certo!».\n",
            "Rispuosemi: «Non omo, omo già fui,\n",
            "e li parenti miei furon lombardi,\n",
            "mantoani per patrïa ambedui.\n",
            "Nacqui\n",
            "e vissi a Roma sotto ’l buono Augusto\n",
            "nel tempo de li dèi falsi e bugiardi.\n",
            "Poeta fui, e cantai di quel giusto\n",
            "figliuol d’Anchise che venne di Troia,\n",
            "poi che ’l superbo Ilión fu combusto.\n",
            "Ma tu perché ritorni a tanta noia?\n",
            "perché non sali il dilettoso monte\n",
            "ch’è principio e cagion di tutta gioia?».\n",
            "«Or se’ tu quel Virgilio e quella fonte\n",
            "che spandi di parlar sì largo fiume?»,\n",
            "rispuos’ io lui con vergognosa fronte.\n",
            "«O de li altri poeti onore e lume\n",
            "vagliami ’l lungo studio e ’l grande amore\n",
            "che m’ha fatto cercar lo tuo volume.\n",
            "Tu se’ lo mio maestro e ’l mio autore;\n",
            "tu se’ solo colui da cu’ io tolsi\n",
            "lo bello stilo che m’ha fatto onore.\n",
            "Vedi la bestia per cu’ io mi volsi:\n",
            "aiutami da lei, famoso saggio,\n",
            "ch’ella mi fa tremar le vene e i polsi».\n",
            "«A te convien tenere altro vïaggio»,\n",
            "rispuose poi che lagrimar mi vide,\n",
            "«se vuo’ campar d’esto loco selvaggio;\n",
            "ché questa bestia, per la qual tu gride,\n",
            "non lascia altrui passar per la sua via,\n",
            "ma tanto lo ’mpedisce che l’uccide;\n",
            "e ha natura sì malvagia e ria,\n",
            "che mai non empie la bramosa voglia,\n",
            "e dopo ’l pasto ha più fame che pria.\n",
            "Molti son li animali a cui s’ammoglia,\n",
            "e più saranno ancora, infin che ’l veltro\n",
            "verrà, che la farà morir con doglia.\n",
            "Questi non ciberà terra né peltro,\n",
            "ma sapïenza, amore e virtute,\n",
            "e sua nazion sarà tra feltro e feltro.\n",
            "Di quella umile Italia fia salute\n",
            "per cui morì la vergine Cammilla,\n",
            "Eurialo e Turno e Niso di ferute.\n",
            "Questi la caccerà per ogne villa,\n",
            "fin che l’avrà rimessa ne lo ’nferno,\n",
            "là onde ’nvidia prima dipartilla.\n",
            "Ond’ io per lo tuo me’ penso e discerno\n",
            "che tu mi segui, e io sarò tua guida,\n",
            "e trarrotti di qui per loco etterno,\n",
            "ove udirai le disperate strida,\n",
            "vedrai li antichi spiriti dolenti,\n",
            "ch’a la seconda morte ciascun grida;\n",
            "e vederai color che son contenti\n",
            "nel foco, perché speran di venire\n",
            "quando che sia a le beate genti.\n",
            "A le quai poi se tu vorrai salire,\n",
            "anima fia a ciò più di me degna:\n",
            "con lei ti lascerò nel mio partire;\n",
            "ché quello imperador che là sù regna,\n",
            "perch’ i’ fu’ ribellante a la sua legge,\n",
            "non vuol che ’n sua città per me si vegna.\n",
            "In tutte parti impera e quivi regge;\n",
            "quivi è la sua città e l’alto seggio:\n",
            "oh felice colui cu’ ivi elegge!».\n",
            "E io a lui: «Poeta, io ti richeggio\n",
            "per quello Dio che tu non conoscesti,\n",
            "acciò ch’io fugga questo male e peggio,\n",
            "che tu mi meni là dov’or dicesti,\n",
            "sì ch’io veggia la porta di san Pietro\n",
            "e color cui tu fai cotanto mesti».\n",
            "Allor si mosse, e io li tenni dietro.\n",
            "\n",
            "INFERNO CANTO 2\n",
            "Lo giorno se n’andava, e l’aere bruno\n",
            "toglieva li animai che sono in terra\n",
            "da le fatiche loro; e io sol uno\n",
            "m’apparecchiava a sostener la guerra\n",
            "sì del cammino e sì de la pietate,\n",
            "che ritrarrà la mente che non erra.\n",
            "O muse, o alto ingegno, or m’aiutate;\n",
            "o mente che scrivesti ciò ch’io vidi,\n",
            "qui si parrà la tua nobilitate.\n",
            "Io cominciai: «Poeta che mi guidi,\n",
            "guarda la mia virtù s’ell’ è possente,\n",
            "prima ch’a l’alto passo tu mi fidi.\n",
            "Tu dici che di Silvïo il parente,\n",
            "corruttibile ancora, ad immortale\n",
            "secolo andò, e fu sensibilmente.\n",
            "Però, se l’avversario d’ogne male\n",
            "cortese i fu, pensando l’alto effetto\n",
            "ch’uscir dovea di lui e ’l chi e ’l quale\n",
            "non pare indegno ad omo d’intelletto;\n",
            "ch’e’ fu de l’alma Roma e di suo impero\n",
            "ne l’empireo ciel per padre eletto:\n",
            "la quale e ’l quale, a voler dir lo vero,\n",
            "fu stabilita per lo loco santo\n",
            "u’ siede il successor del maggior Piero.\n",
            "Per quest’ andata onde li dai tu vanto,\n",
            "intese cose che furon cagione\n",
            "di sua vittoria e del papale ammanto.\n",
            "Andovvi poi lo Vas d’elezïone,\n",
            "per recarne conforto a quella fede\n",
            "ch’è principio a la via di salvazione.\n",
            "Ma io, perché venirvi? o chi ’l concede?\n",
            "Io non Enëa, io non Paulo sono;\n",
            "me degno a ciò né io né altri ’l crede.\n",
            "Per che, se del venire io m’abbandono,\n",
            "temo che la venuta non sia folle.\n",
            "Se’ savio; intendi me’ ch’i’ non ragiono».\n",
            "E qual è quei che disvuol ciò che volle\n",
            "e per novi pensier cangia proposta,\n",
            "sì che dal cominciar tutto si tolle,\n",
            "tal mi fec’ ïo ’n quella oscura costa,\n",
            "perché, pensando, consumai la ’mpresa\n",
            "che fu nel cominciar cotanto tosta.\n",
            "«S’i’ ho ben la parola tua intesa»,\n",
            "rispuose del magnanimo quell’ ombra;\n",
            "«l’anima tua è da viltade offesa;\n",
            "la qual molte fïate l’ omo ingombra\n",
            "sì che d’onrata impresa lo rivolve,\n",
            "come falso veder bestia quand’ ombra.\n",
            "Da questa tema acciò che tu ti solve,\n",
            "dirotti perch’ io venni e quel ch’io ’ntesi\n",
            "nel primo punto che di te mi dolve.\n",
            "Io era tra color che son sospesi,\n",
            "e donna mi chiamò beata e bella,\n",
            "tal che di comandare io la richiesi.\n",
            "Lucevan li occhi suoi più che la stella;\n",
            "e cominciommi a dir soave e piana,\n",
            "con angelica voce, in sua favella:\n",
            "“O anima cortese mantoana,\n",
            "di cui la fama ancor nel mondo dura,\n",
            "e durerà quanto ’l mondo lontana,\n",
            "l’amico mio, e non de la ventura,\n",
            "ne la diserta piaggia è impedito\n",
            "sì nel cammin, che volt’ è per paura;\n",
            "e temo che non sia già sì smarrito,\n",
            "ch’io mi sia tardi al soccorso levata,\n",
            "per quel ch’i’ ho di lui nel cielo udito.\n",
            "Or movi, e con la tua parola ornata\n",
            "e con ciò c’ha mestieri al suo campare,\n",
            "l’aiuta, sì ch’i’ ne sia consolata.\n",
            "I’ son Beatrice che ti faccio andare;\n",
            "vegno del loco ove tornar disio;\n",
            "amor mi mosse, che mi fa parlare.\n",
            "Quando sarò dinanzi al segnor mio,\n",
            "di te mi loderò sovente a lui”.\n",
            "Tacette allora, e poi comincia’ io:\n",
            "“O donna di virtù, sola per cui\n",
            "l’umana spezie eccede ogne contento\n",
            "di quel ciel c’ha minor li cerchi sui,\n",
            "tanto m’aggrada il tuo comandamento,\n",
            "che l’ubidir, se già fosse, m’è tardi;\n",
            "più non t’è uo’ ch’aprirmi il tuo talento.\n",
            "Ma dimmi la cagion che non ti guardi\n",
            "de lo scender qua giuso in questo centro\n",
            "de l’ampio loco ove tornar tu ardi”.\n",
            "“Da che tu vuo’ saver cotanto a dentro,\n",
            "dirotti brievemente”, mi rispuose,\n",
            "“perch’ i’ non temo di venir qua entro.\n",
            "Temer si dee di sole quelle cose\n",
            "c’hanno potenza di fare altrui male;\n",
            "de l’altre no, ché non son paurose.\n",
            "I’ son fatta da Dio, sua mercé, tale,\n",
            "che la vostra miseria non mi tange,\n",
            "né fiamma d’esto ’ncendio non m’assale.\n",
            "Donna è gentil nel ciel che si compiange\n",
            "di questo ’mpedimento ov’ io ti mando,\n",
            "sì che duro giudicio là sù frange.\n",
            "Questa chiese Lucia in suo dimando\n",
            "e disse: – Or ha bisogno il tuo fedele\n",
            "di te, e io a te lo raccomando -.\n",
            "Lucia, nimica di ciascun crudele,\n",
            "si mosse, e venne al loco dov’ i’ era,\n",
            "che mi sedea con l’antica Rachele.\n",
            "Disse: – Beatrice, loda di Dio vera,\n",
            "ché non soccorri quei che t’amò tanto,\n",
            "ch’uscì per te de la volgare schiera?\n",
            "Non odi tu la pieta del suo pianto,\n",
            "non vedi tu la morte che ’l combatte\n",
            "su la fiumana ove ’l mar non ha vanto? -.\n",
            "Al mondo non fur mai persone ratte\n",
            "a far lor pro o a fuggir lor danno,\n",
            "com’ io, dopo cotai parole fatte,\n",
            "venni qua giù del mio beato scanno,\n",
            "fidandomi del tuo parlare onesto,\n",
            "ch’onora te e quei ch’udito l’hanno”.\n",
            "Poscia che m’ebbe ragionato questo,\n",
            "li occhi lucenti lacrimando volse,\n",
            "per che mi fece del venir più presto.\n",
            "E venni a te così com’ ella volse;\n",
            "d’inanzi a quella fiera ti levai\n",
            "che del bel monte il corto andar ti tolse.\n",
            "Dunque: che è? perché, perché restai,\n",
            "perché tanta viltà nel core allette,\n",
            "perché ardire e franchezza non hai,\n",
            "poscia che tai tre donne benedette\n",
            "curan di te ne la corte del cielo,\n",
            "e ‘l mio parlar tanto ben ti promette?».\n",
            "Quali fioretti dal notturno gelo\n",
            "chinati e chiusi, poi che ’l sol li ’mbianca\n",
            "si drizzan tutti aperti in loro stelo,\n",
            "tal mi fec’ io di mia virtude stanca,\n",
            "e tanto buono ardire al cor mi corse,\n",
            "ch’i’ cominciai come persona franca:\n",
            "«Oh pietosa colei che mi soccorse!\n",
            "e te cortese ch’ubidisti tosto\n",
            "a le vere parole che ti porse!\n",
            "Tu m’hai con disiderio il cor disposto\n",
            "sì al venir con le parole tue,\n",
            "ch’i’ son tornato nel primo pr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "LEkjHdjVsnbK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "2lbhlkQGtA2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199c60f5-71d1-4f0e-f489-f58d0a87a0f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !'(),-.0123456789:;?ABCDEFGHILMNOPQRSTUVZabcdefghijlmnopqrstuvxyz «»ÈËÏàäèéëìïòóöùü–—‘’“”…﻿\n",
            "93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)}"
      ],
      "metadata": {
        "id": "nuFqu7GOzTvK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}"
      ],
      "metadata": {
        "id": "ca6wfT_wuCj-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda x : [stoi[ch] for ch in x]\n",
        "decode = lambda x : ''.join([itos[i] for i in x])"
      ],
      "metadata": {
        "id": "D-tYhUihzcVa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode('Nel mezzo del cammin'))"
      ],
      "metadata": {
        "id": "I0GmeEENuyhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d22815f-5d9e-4126-aee5-2d92d841af98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33, 47, 53, 1, 54, 47, 66, 66, 56, 1, 46, 47, 53, 1, 45, 43, 54, 54, 51, 55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "edAktZYGw1NX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)"
      ],
      "metadata": {
        "id": "66LD44jpzyVB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape, data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgE06JSTz4Sq",
        "outputId": "5e998a60-476c-4608-b085-204a6f768827"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([416980]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ],
      "metadata": {
        "id": "b9jaBdnk0Eiy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  print(\"context:\", x[:t+1])\n",
        "  print(\"target: \", y[t].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEXMKf4V0R67",
        "outputId": "e8048454-ca23-4521-8291-c28bb1f25f9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: tensor([30])\n",
            "target:  33\n",
            "context: tensor([30, 33])\n",
            "target:  27\n",
            "context: tensor([30, 33, 27])\n",
            "target:  26\n",
            "context: tensor([30, 33, 27, 26])\n",
            "target:  37\n",
            "context: tensor([30, 33, 27, 26, 37])\n",
            "target:  33\n",
            "context: tensor([30, 33, 27, 26, 37, 33])\n",
            "target:  34\n",
            "context: tensor([30, 33, 27, 26, 37, 33, 34])\n",
            "target:  1\n",
            "context: tensor([30, 33, 27, 26, 37, 33, 34,  1])\n",
            "target:  24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def get_batch(split='train', batch_size=32, block_size=8):\n",
        "  data = train_data if split=='train' else test_data\n",
        "  ix = torch.randint(low=0, high=(len(data) - block_size), size=(batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  y = torch.clamp(y, 0, vocab_size - 1)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "q2W8GtBu0vOM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train', batch_size=4, block_size=8)"
      ],
      "metadata": {
        "id": "0j7p9W3I1hK_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb.shape, xb, sep='\\n')\n",
        "print(yb.shape, yb, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGdxIBNL13Ni",
        "outputId": "0ed626b3-a673-43ba-b5cb-1b6208a567da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n",
            "tensor([[48, 59, 47, 46, 46, 56,  1, 43],\n",
            "        [47,  6,  1, 55, 56, 55,  1, 60],\n",
            "        [49, 56, 54, 47, 55, 61, 51, 19],\n",
            "        [51, 43,  1, 61, 47, 49, 49, 50]])\n",
            "torch.Size([4, 8])\n",
            "tensor([[59, 47, 46, 46, 56,  1, 43, 55],\n",
            "        [ 6,  1, 55, 56, 55,  1, 60, 43],\n",
            "        [56, 54, 47, 55, 61, 51, 19,  1],\n",
            "        [43,  1, 61, 47, 49, 49, 50, 51]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "for b in range(8):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b, t]\n",
        "    print(f\"when the context is {context} then the target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMXFd0xY3GG3",
        "outputId": "a29b3780-4cd5-4e04-b373-29ebd7ef56a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when the context is tensor([63]) then the target is 51\n",
            "when the context is tensor([63, 51]) then the target is 47\n",
            "when the context is tensor([63, 51, 47]) then the target is 61\n",
            "when the context is tensor([63, 51, 47, 61]) then the target is 56\n",
            "when the context is tensor([63, 51, 47, 61, 56]) then the target is 6\n",
            "when the context is tensor([63, 51, 47, 61, 56,  6]) then the target is 0\n",
            "when the context is tensor([63, 51, 47, 61, 56,  6,  0]) then the target is 46\n",
            "when the context is tensor([63, 51, 47, 61, 56,  6,  0, 46]) then the target is 51\n",
            "when the context is tensor([54]) then the target is 51\n",
            "when the context is tensor([54, 51]) then the target is 49\n",
            "when the context is tensor([54, 51, 49]) then the target is 53\n",
            "when the context is tensor([54, 51, 49, 53]) then the target is 51\n",
            "when the context is tensor([54, 51, 49, 53, 51]) then the target is 43\n",
            "when the context is tensor([54, 51, 49, 53, 51, 43]) then the target is 55\n",
            "when the context is tensor([54, 51, 49, 53, 51, 43, 55]) then the target is 61\n",
            "when the context is tensor([54, 51, 49, 53, 51, 43, 55, 61]) then the target is 47\n",
            "when the context is tensor([43]) then the target is 46\n",
            "when the context is tensor([43, 46]) then the target is 51\n",
            "when the context is tensor([43, 46, 51]) then the target is 1\n",
            "when the context is tensor([43, 46, 51,  1]) then the target is 51\n",
            "when the context is tensor([43, 46, 51,  1, 51]) then the target is 55\n",
            "when the context is tensor([43, 46, 51,  1, 51, 55]) then the target is 55\n",
            "when the context is tensor([43, 46, 51,  1, 51, 55, 55]) then the target is 43\n",
            "when the context is tensor([43, 46, 51,  1, 51, 55, 55, 43]) then the target is 55\n",
            "when the context is tensor([1]) then the target is 53\n",
            "when the context is tensor([ 1, 53]) then the target is 43\n",
            "when the context is tensor([ 1, 53, 43]) then the target is 1\n",
            "when the context is tensor([ 1, 53, 43,  1]) then the target is 54\n",
            "when the context is tensor([ 1, 53, 43,  1, 54]) then the target is 47\n",
            "when the context is tensor([ 1, 53, 43,  1, 54, 47]) then the target is 55\n",
            "when the context is tensor([ 1, 53, 43,  1, 54, 47, 55]) then the target is 61\n",
            "when the context is tensor([ 1, 53, 43,  1, 54, 47, 55, 61]) then the target is 47\n",
            "when the context is tensor([1]) then the target is 24\n",
            "when the context is tensor([ 1, 24]) then the target is 51\n",
            "when the context is tensor([ 1, 24, 51]) then the target is 59\n",
            "when the context is tensor([ 1, 24, 51, 59]) then the target is 56\n",
            "when the context is tensor([ 1, 24, 51, 59, 56]) then the target is 19\n",
            "when the context is tensor([ 1, 24, 51, 59, 56, 19]) then the target is 0\n",
            "when the context is tensor([ 1, 24, 51, 59, 56, 19,  0]) then the target is 68\n",
            "when the context is tensor([ 1, 24, 51, 59, 56, 19,  0, 68]) then the target is 38\n",
            "when the context is tensor([45]) then the target is 45\n",
            "when the context is tensor([45, 45]) then the target is 50\n",
            "when the context is tensor([45, 45, 50]) then the target is 51\n",
            "when the context is tensor([45, 45, 50, 51]) then the target is 56\n",
            "when the context is tensor([45, 45, 50, 51, 56]) then the target is 8\n",
            "when the context is tensor([45, 45, 50, 51, 56,  8]) then the target is 0\n",
            "when the context is tensor([45, 45, 50, 51, 56,  8,  0]) then the target is 24\n",
            "when the context is tensor([45, 45, 50, 51, 56,  8,  0, 24]) then the target is 56\n",
            "when the context is tensor([50]) then the target is 51\n",
            "when the context is tensor([50, 51]) then the target is 62\n",
            "when the context is tensor([50, 51, 62]) then the target is 46\n",
            "when the context is tensor([50, 51, 62, 46]) then the target is 47\n",
            "when the context is tensor([50, 51, 62, 46, 47]) then the target is 20\n",
            "when the context is tensor([50, 51, 62, 46, 47, 20]) then the target is 1\n",
            "when the context is tensor([50, 51, 62, 46, 47, 20,  1]) then the target is 47\n",
            "when the context is tensor([50, 51, 62, 46, 47, 20,  1, 47]) then the target is 1\n",
            "when the context is tensor([1]) then the target is 57\n",
            "when the context is tensor([ 1, 57]) then the target is 62\n",
            "when the context is tensor([ 1, 57, 62]) then the target is 59\n",
            "when the context is tensor([ 1, 57, 62, 59]) then the target is 1\n",
            "when the context is tensor([ 1, 57, 62, 59,  1]) then the target is 45\n",
            "when the context is tensor([ 1, 57, 62, 59,  1, 45]) then the target is 50\n",
            "when the context is tensor([ 1, 57, 62, 59,  1, 45, 50]) then the target is 88\n",
            "when the context is tensor([ 1, 57, 62, 59,  1, 45, 50, 88]) then the target is 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class naiveLM(nn.Module):\n",
        "  def __init__(self, vocab_size, latent_space_dim):\n",
        "    super().__init__()\n",
        "    self.embedding_table = nn.Embedding(vocab_size, latent_space_dim)\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(in_features=latent_space_dim, out_features=latent_space_dim, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=latent_space_dim, out_features=latent_space_dim, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=latent_space_dim, out_features=latent_space_dim, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=latent_space_dim, out_features=vocab_size, bias=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, idx):\n",
        "    emb = self.embedding_table(idx)\n",
        "    logits = self.net(emb)\n",
        "    return logits\n",
        "\n",
        "  def compute_loss(self, idx, targets):\n",
        "    logits = self.forward(idx)\n",
        "    B, T, C = logits.shape\n",
        "    logits = logits.view(B*T, C)\n",
        "    targets = targets.view(B*T)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "    return loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens=32):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits = self.forward(idx) # B, T, C\n",
        "      logits = logits[:, -1, :] # B, C\n",
        "      probs = F.softmax(logits, dim=-1) # B, C\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # idx: (B, T) --> (B, T+1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "zklkoveE3pOU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = naiveLM(vocab_size=vocab_size, latent_space_dim=32)"
      ],
      "metadata": {
        "id": "0cXG8nC65ETL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb.shape, xb, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4TM9dYl_L1t",
        "outputId": "d8c81203-c444-4ae3-e4ba-b8da30c408bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8])\n",
            "tensor([[63, 51, 47, 61, 56,  6,  0, 46],\n",
            "        [54, 51, 49, 53, 51, 43, 55, 61],\n",
            "        [43, 46, 51,  1, 51, 55, 55, 43],\n",
            "        [ 1, 53, 43,  1, 54, 47, 55, 61],\n",
            "        [ 1, 24, 51, 59, 56, 19,  0, 68],\n",
            "        [45, 45, 50, 51, 56,  8,  0, 24],\n",
            "        [50, 51, 62, 46, 47, 20,  1, 47],\n",
            "        [ 1, 57, 62, 59,  1, 45, 50, 88],\n",
            "        [54, 47,  0, 60, 56, 61, 61, 56],\n",
            "        [56,  1, 61, 59, 43,  1, 45, 56],\n",
            "        [56, 54, 43, 55, 46, 56, 53, 53],\n",
            "        [ 0, 63, 51, 46, 51,  1, 60, 78],\n",
            "        [56, 45, 56,  1, 46, 51,  1, 63],\n",
            "        [51,  1, 58, 62, 47, 53, 53, 56],\n",
            "        [ 1, 61, 47,  1, 46, 43,  1, 61],\n",
            "        [ 1, 57, 51, 83,  1, 53, 56,  1],\n",
            "        [ 1, 51, 55, 61, 43, 49, 53, 51],\n",
            "        [47, 61, 43,  6,  1, 68, 51, 56],\n",
            "        [43,  1, 26, 58, 62, 43, 61, 56],\n",
            "        [62, 56, 51,  1, 47, 61, 61, 47],\n",
            "        [43,  1, 55, 88, 47, 59, 43,  1],\n",
            "        [61, 61, 47,  1, 46, 88, 43, 54],\n",
            "        [ 8,  0, 24, 51, 80,  1, 45, 50],\n",
            "        [53, 43,  1, 63, 56, 45, 47,  1],\n",
            "        [53, 43,  1, 53, 62, 60, 60, 62],\n",
            "        [ 6,  1, 43, 45, 45, 51, 80,  1],\n",
            "        [43, 47, 60, 61, 59, 56,  1, 43],\n",
            "        [43,  1, 48, 51, 47, 59, 43,  1],\n",
            "        [62, 59, 43,  1, 45, 56, 60, 61],\n",
            "        [55, 51, 59,  1, 45, 56, 55,  1],\n",
            "        [47, 53,  1, 45, 51, 47, 53, 56],\n",
            "        [50, 47,  1, 54, 43, 51,  1, 60]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.forward(xb)"
      ],
      "metadata": {
        "id": "Q5yNcWIt6w8k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits.shape, logits, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMGujrDb_Q42",
        "outputId": "92bf34e2-07d4-4f94-db40-a6f8fcc45c22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 93])\n",
            "tensor([[[ 1.7708e-02, -9.5454e-02, -6.3445e-02,  ...,  2.8933e-02,\n",
            "           1.2723e-01,  7.2484e-02],\n",
            "         [ 4.0687e-02, -1.5867e-01, -9.0586e-02,  ...,  2.8630e-02,\n",
            "           1.6466e-01,  1.2058e-02],\n",
            "         [-6.1758e-03, -1.2827e-01, -6.2576e-02,  ...,  6.6480e-03,\n",
            "           9.5547e-02,  9.9728e-02],\n",
            "         ...,\n",
            "         [-2.3439e-03, -8.5113e-02, -7.8333e-02,  ..., -1.1967e-02,\n",
            "           1.6515e-01,  1.2914e-04],\n",
            "         [-4.0942e-02, -7.1079e-02, -7.6534e-02,  ...,  1.6888e-02,\n",
            "           1.5284e-01,  5.9717e-03],\n",
            "         [ 3.3854e-02, -1.0048e-01, -8.2002e-02,  ...,  5.4976e-03,\n",
            "           1.5675e-01,  2.9277e-02]],\n",
            "\n",
            "        [[ 1.2351e-02, -8.8411e-02, -9.7834e-02,  ...,  1.4341e-02,\n",
            "           2.0603e-01, -2.7528e-02],\n",
            "         [ 4.0687e-02, -1.5867e-01, -9.0586e-02,  ...,  2.8630e-02,\n",
            "           1.6466e-01,  1.2058e-02],\n",
            "         [-6.5279e-03, -9.1783e-02, -6.9481e-02,  ...,  3.1910e-03,\n",
            "           1.4682e-01,  2.3473e-02],\n",
            "         ...,\n",
            "         [-4.7691e-02, -7.6781e-02, -9.4553e-02,  ...,  1.5734e-02,\n",
            "           1.6388e-01, -3.0914e-03],\n",
            "         [-2.0732e-02, -9.0103e-02, -5.8257e-02,  ...,  3.4678e-02,\n",
            "           1.5403e-01,  2.6134e-02],\n",
            "         [ 4.4188e-03, -1.0904e-01, -3.9501e-02,  ...,  2.2420e-02,\n",
            "           1.5957e-01,  7.3960e-03]],\n",
            "\n",
            "        [[-4.7691e-02, -7.6781e-02, -9.4553e-02,  ...,  1.5734e-02,\n",
            "           1.6388e-01, -3.0914e-03],\n",
            "         [ 3.3854e-02, -1.0048e-01, -8.2002e-02,  ...,  5.4976e-03,\n",
            "           1.5675e-01,  2.9277e-02],\n",
            "         [ 4.0687e-02, -1.5867e-01, -9.0586e-02,  ...,  2.8630e-02,\n",
            "           1.6466e-01,  1.2058e-02],\n",
            "         ...,\n",
            "         [-2.0732e-02, -9.0103e-02, -5.8257e-02,  ...,  3.4678e-02,\n",
            "           1.5403e-01,  2.6134e-02],\n",
            "         [-2.0732e-02, -9.0103e-02, -5.8257e-02,  ...,  3.4678e-02,\n",
            "           1.5403e-01,  2.6134e-02],\n",
            "         [-4.7691e-02, -7.6781e-02, -9.4553e-02,  ...,  1.5734e-02,\n",
            "           1.6388e-01, -3.0914e-03]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.0732e-02, -9.0103e-02, -5.8257e-02,  ...,  3.4678e-02,\n",
            "           1.5403e-01,  2.6134e-02],\n",
            "         [ 4.0687e-02, -1.5867e-01, -9.0586e-02,  ...,  2.8630e-02,\n",
            "           1.6466e-01,  1.2058e-02],\n",
            "         [-1.6982e-02, -9.0207e-02, -5.6442e-02,  ...,  2.2589e-02,\n",
            "           1.4553e-01,  2.5142e-02],\n",
            "         ...,\n",
            "         [-5.7230e-02, -6.2998e-02, -6.7384e-02,  ...,  3.5913e-02,\n",
            "           1.6782e-01,  3.6845e-02],\n",
            "         [-2.0732e-02, -9.0103e-02, -5.8257e-02,  ...,  3.4678e-02,\n",
            "           1.5403e-01,  2.6134e-02],\n",
            "         [ 1.8197e-02, -1.0761e-01, -6.5599e-02,  ..., -1.5988e-03,\n",
            "           1.3854e-01,  3.7693e-02]],\n",
            "\n",
            "        [[-6.1758e-03, -1.2827e-01, -6.2576e-02,  ...,  6.6480e-03,\n",
            "           9.5547e-02,  9.9728e-02],\n",
            "         [ 6.9752e-02, -1.4752e-01, -7.2193e-02,  ...,  1.7235e-02,\n",
            "           1.1076e-01,  5.1851e-02],\n",
            "         [ 1.8197e-02, -1.0761e-01, -6.5599e-02,  ..., -1.5988e-03,\n",
            "           1.3854e-01,  3.7693e-02],\n",
            "         ...,\n",
            "         [-6.1758e-03, -1.2827e-01, -6.2576e-02,  ...,  6.6480e-03,\n",
            "           9.5547e-02,  9.9728e-02],\n",
            "         [ 6.9752e-02, -1.4752e-01, -7.2193e-02,  ...,  1.7235e-02,\n",
            "           1.1076e-01,  5.1851e-02],\n",
            "         [-5.7230e-02, -6.2998e-02, -6.7384e-02,  ...,  3.5913e-02,\n",
            "           1.6782e-01,  3.6845e-02]],\n",
            "\n",
            "        [[ 6.1805e-02, -1.5226e-01, -8.0704e-02,  ...,  1.6021e-02,\n",
            "           1.4450e-01,  1.5569e-02],\n",
            "         [-6.1758e-03, -1.2827e-01, -6.2576e-02,  ...,  6.6480e-03,\n",
            "           9.5547e-02,  9.9728e-02],\n",
            "         [ 1.8197e-02, -1.0761e-01, -6.5599e-02,  ..., -1.5988e-03,\n",
            "           1.3854e-01,  3.7693e-02],\n",
            "         ...,\n",
            "         [ 4.0687e-02, -1.5867e-01, -9.0586e-02,  ...,  2.8630e-02,\n",
            "           1.6466e-01,  1.2058e-02],\n",
            "         [ 1.8197e-02, -1.0761e-01, -6.5599e-02,  ..., -1.5988e-03,\n",
            "           1.3854e-01,  3.7693e-02],\n",
            "         [-1.0405e-02, -1.1730e-01, -1.0871e-01,  ...,  1.2088e-02,\n",
            "           1.7158e-01,  2.9883e-02]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb.shape, xb, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seoEdu_tApjh",
        "outputId": "1ec81fe4-ad2b-454f-8bd1-e9e1220d1def"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8])\n",
            "tensor([[63, 51, 47, 61, 56,  6,  0, 46],\n",
            "        [54, 51, 49, 53, 51, 43, 55, 61],\n",
            "        [43, 46, 51,  1, 51, 55, 55, 43],\n",
            "        [ 1, 53, 43,  1, 54, 47, 55, 61],\n",
            "        [ 1, 24, 51, 59, 56, 19,  0, 68],\n",
            "        [45, 45, 50, 51, 56,  8,  0, 24],\n",
            "        [50, 51, 62, 46, 47, 20,  1, 47],\n",
            "        [ 1, 57, 62, 59,  1, 45, 50, 88],\n",
            "        [54, 47,  0, 60, 56, 61, 61, 56],\n",
            "        [56,  1, 61, 59, 43,  1, 45, 56],\n",
            "        [56, 54, 43, 55, 46, 56, 53, 53],\n",
            "        [ 0, 63, 51, 46, 51,  1, 60, 78],\n",
            "        [56, 45, 56,  1, 46, 51,  1, 63],\n",
            "        [51,  1, 58, 62, 47, 53, 53, 56],\n",
            "        [ 1, 61, 47,  1, 46, 43,  1, 61],\n",
            "        [ 1, 57, 51, 83,  1, 53, 56,  1],\n",
            "        [ 1, 51, 55, 61, 43, 49, 53, 51],\n",
            "        [47, 61, 43,  6,  1, 68, 51, 56],\n",
            "        [43,  1, 26, 58, 62, 43, 61, 56],\n",
            "        [62, 56, 51,  1, 47, 61, 61, 47],\n",
            "        [43,  1, 55, 88, 47, 59, 43,  1],\n",
            "        [61, 61, 47,  1, 46, 88, 43, 54],\n",
            "        [ 8,  0, 24, 51, 80,  1, 45, 50],\n",
            "        [53, 43,  1, 63, 56, 45, 47,  1],\n",
            "        [53, 43,  1, 53, 62, 60, 60, 62],\n",
            "        [ 6,  1, 43, 45, 45, 51, 80,  1],\n",
            "        [43, 47, 60, 61, 59, 56,  1, 43],\n",
            "        [43,  1, 48, 51, 47, 59, 43,  1],\n",
            "        [62, 59, 43,  1, 45, 56, 60, 61],\n",
            "        [55, 51, 59,  1, 45, 56, 55,  1],\n",
            "        [47, 53,  1, 45, 51, 47, 53, 56],\n",
            "        [50, 47,  1, 54, 43, 51,  1, 60]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yb.shape, yb, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Yzqu1cAlbp",
        "outputId": "ad2fad1b-eaae-48e9-8c87-f9099b9e8049"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8])\n",
            "tensor([[51, 47, 61, 56,  6,  0, 46, 51],\n",
            "        [51, 49, 53, 51, 43, 55, 61, 47],\n",
            "        [46, 51,  1, 51, 55, 55, 43, 55],\n",
            "        [53, 43,  1, 54, 47, 55, 61, 47],\n",
            "        [24, 51, 59, 56, 19,  0, 68, 38],\n",
            "        [45, 50, 51, 56,  8,  0, 24, 56],\n",
            "        [51, 62, 46, 47, 20,  1, 47,  1],\n",
            "        [57, 62, 59,  1, 45, 50, 88, 51],\n",
            "        [47,  0, 60, 56, 61, 61, 56,  1],\n",
            "        [ 1, 61, 59, 43,  1, 45, 56, 61],\n",
            "        [54, 43, 55, 46, 56, 53, 53, 56],\n",
            "        [63, 51, 46, 51,  1, 60, 78,  1],\n",
            "        [45, 56,  1, 46, 51,  1, 63, 51],\n",
            "        [ 1, 58, 62, 47, 53, 53, 56,  1],\n",
            "        [61, 47,  1, 46, 43,  1, 61, 62],\n",
            "        [57, 51, 83,  1, 53, 56,  1, 88],\n",
            "        [51, 55, 61, 43, 49, 53, 51, 43],\n",
            "        [61, 43,  6,  1, 68, 51, 56,  1],\n",
            "        [ 1, 26, 58, 62, 43, 61, 56, 59],\n",
            "        [56, 51,  1, 47, 61, 61, 47, 59],\n",
            "        [ 1, 55, 88, 47, 59, 43,  1, 60],\n",
            "        [61, 47,  1, 46, 88, 43, 54, 56],\n",
            "        [ 0, 24, 51, 80,  1, 45, 50, 47],\n",
            "        [43,  1, 63, 56, 45, 47,  1, 47],\n",
            "        [43,  1, 53, 62, 60, 60, 62, 59],\n",
            "        [ 1, 43, 45, 45, 51, 80,  1, 45],\n",
            "        [47, 60, 61, 59, 56,  1, 43,  1],\n",
            "        [ 1, 48, 51, 47, 59, 43,  1, 43],\n",
            "        [59, 43,  1, 45, 56, 60, 61, 43],\n",
            "        [51, 59,  1, 45, 56, 55,  1, 53],\n",
            "        [53,  1, 45, 51, 47, 53, 56,  6],\n",
            "        [47,  1, 54, 43, 51,  1, 60, 88]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.compute_loss(xb, yb)"
      ],
      "metadata": {
        "id": "Vb5Ydm9PAhb9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4tKMWlx9OYi",
        "outputId": "e0170d6d-8eb8-40d6-ea9b-6b58547bd4d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.5208, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2UsaQWXCLwo",
        "outputId": "da6cd985-e07c-452a-d3ac-795b2e6e92d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[63, 51, 47, 61, 56,  6,  0, 46],\n",
            "        [54, 51, 49, 53, 51, 43, 55, 61],\n",
            "        [43, 46, 51,  1, 51, 55, 55, 43],\n",
            "        [ 1, 53, 43,  1, 54, 47, 55, 61],\n",
            "        [ 1, 24, 51, 59, 56, 19,  0, 68],\n",
            "        [45, 45, 50, 51, 56,  8,  0, 24],\n",
            "        [50, 51, 62, 46, 47, 20,  1, 47],\n",
            "        [ 1, 57, 62, 59,  1, 45, 50, 88],\n",
            "        [54, 47,  0, 60, 56, 61, 61, 56],\n",
            "        [56,  1, 61, 59, 43,  1, 45, 56],\n",
            "        [56, 54, 43, 55, 46, 56, 53, 53],\n",
            "        [ 0, 63, 51, 46, 51,  1, 60, 78],\n",
            "        [56, 45, 56,  1, 46, 51,  1, 63],\n",
            "        [51,  1, 58, 62, 47, 53, 53, 56],\n",
            "        [ 1, 61, 47,  1, 46, 43,  1, 61],\n",
            "        [ 1, 57, 51, 83,  1, 53, 56,  1],\n",
            "        [ 1, 51, 55, 61, 43, 49, 53, 51],\n",
            "        [47, 61, 43,  6,  1, 68, 51, 56],\n",
            "        [43,  1, 26, 58, 62, 43, 61, 56],\n",
            "        [62, 56, 51,  1, 47, 61, 61, 47],\n",
            "        [43,  1, 55, 88, 47, 59, 43,  1],\n",
            "        [61, 61, 47,  1, 46, 88, 43, 54],\n",
            "        [ 8,  0, 24, 51, 80,  1, 45, 50],\n",
            "        [53, 43,  1, 63, 56, 45, 47,  1],\n",
            "        [53, 43,  1, 53, 62, 60, 60, 62],\n",
            "        [ 6,  1, 43, 45, 45, 51, 80,  1],\n",
            "        [43, 47, 60, 61, 59, 56,  1, 43],\n",
            "        [43,  1, 48, 51, 47, 59, 43,  1],\n",
            "        [62, 59, 43,  1, 45, 56, 60, 61],\n",
            "        [55, 51, 59,  1, 45, 56, 55,  1],\n",
            "        [47, 53,  1, 45, 51, 47, 53, 56],\n",
            "        [50, 47,  1, 54, 43, 51,  1, 60]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEe24la9_Z2w",
        "outputId": "a8381ee4-c72f-47d0-c099-3027a56d4f02"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ",ìp…üüCVj ;\n",
            "…Ë–3e﻿5Rù»»E7èFìBùGmILSÈ2xÏ.n“3rrb:?èii–4vaN﻿NÈ(ìï«…R﻿Q””hF)F»n9–﻿ög«ayf—ù8ón4—?ZÏ9“äOiàlG6﻿,pEéPqm e;èpUï-èADnA-è0(–»om6…Ré.g8 vH8…p;1B2ëmZ 7;jZBöt\n",
            "FùÏä»ù4ìQìb’px—FMPbvzu»Vx5GZvÈ:P:hi:ëómäF﻿ ;ëb﻿G–3-TàAFa'CO»u6FqëxB-4ò”Ëvu… 8dqìfïaö24rï;ëqiPès2TQtA–3Tövs2V–4Ïf—,8a5CbREÈja-Iì8Ëb–-8fAyM9FÈ’ì8uËë)7ìmZqïüZVÏ(ifü–2S‘e–?i-5xL?g?–she?ì9azöU)»äcVSzèq;?geSë«,Zó3Ppàx;q lùx1 :9r8ö6x-1yGPTb7n44eóóébzzZ0T1Nq9Zb'ù–﻿ é8ËU﻿‘“ òàj ùNïaoO0﻿'ìpz?hLn'lyR:i7eRy“ò‘FQzM8ùncòt;öÈ‘l–ürIëNùxbìODïö…lyé;ü“p﻿﻿8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "epochs = 10000\n",
        "for i in range(epochs):\n",
        "\n",
        "  xb, yb = get_batch('loss', batch_size=32, block_size=8)\n",
        "\n",
        "  loss = model.compute_loss(xb, yb)\n",
        "  if i % 1000 == 0: print(loss.item())\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM2xYMwmHUC6",
        "outputId": "216e11aa-a8d5-448c-d825-caeace7373a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.52573299407959\n",
            "2.4445390701293945\n",
            "2.27592396736145\n",
            "2.3547680377960205\n",
            "2.144325017929077\n",
            "2.4452457427978516\n",
            "2.264052152633667\n",
            "2.2559070587158203\n",
            "2.2361109256744385\n",
            "2.373514413833618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noz-MDcYS00r",
        "outputId": "3e75e12f-c8c6-4619-d8b7-ed0923436634"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tuante',\n",
            "ci delerin pri sonchesevie coranere co ardisue lo donto co sego.\n",
            "crdeba ch’ir co ch’ gumenzelordera vutomer de;\n",
            "E e.\n",
            "nderda lal Bëa fll to pe,\n",
            "po tinti ndor ’ l stomeravara mo: mepe, alal cimpo.\n",
            "ineddi luni o ligami\n",
            "E emontal l’ co mma l chesatarco,\n",
            "E cora, aci fatudo l r sì a «el dar prton diche amettte.\n",
            "lurv dedi chere fle na,\n",
            "er ide l’uave voci qua\n",
            "die ’ertte:\n",
            "pomarei\n",
            "ce liso fua nza, peron mpen simbire, splà cheme\n",
            "siù pari ie va ne E tonoll’ive;\n",
            "pre tovido one\n",
            "diss co ttespe i’aconz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SELF ATTENTION DEFINITION\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "B, T, C = 4, 8, 32\n",
        "x = torch.randn(B, T, C) # Embedded batches of senteces\n",
        "\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "K = key(x)\n",
        "Q = query(x)\n",
        "V = value(x)\n",
        "\n",
        "# \"sa\" = \"self attention\"\n",
        "log_sa = Q @ K.transpose(-1, -2)\n",
        "slog_sa = log_sa * head_size**-0.5 # \"s\" = \"scaled\"\n",
        "\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "autoregressive_slog_sa = slog_sa.masked_fill(tril == 0, float('-inf'))\n",
        "self_attention = F.softmax(autoregressive_slog_sa, dim=-1)\n",
        "\n",
        "out = self_attention @ V"
      ],
      "metadata": {
        "id": "_Y6VXj4lT9pV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_attention[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htxIsmP3Uvma",
        "outputId": "13863d82-87f0-48f0-afd1-ae100da8ad2b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4106, 0.5894, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3657, 0.2283, 0.4061, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2168, 0.2759, 0.2204, 0.2870, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2553, 0.1697, 0.1548, 0.2341, 0.1861, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1318, 0.2060, 0.1405, 0.1917, 0.1949, 0.1351, 0.0000, 0.0000],\n",
              "        [0.2137, 0.0978, 0.2374, 0.1025, 0.1418, 0.0838, 0.1230, 0.0000],\n",
              "        [0.0852, 0.1047, 0.0824, 0.1376, 0.1015, 0.1900, 0.1780, 0.1206]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vApTOUEEWZyP",
        "outputId": "97ee28e2-0ca4-4846-f938-d007dceefc8b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self, feat_in, head_size):\n",
        "    super().__init__()\n",
        "    self.feat_in = feat_in\n",
        "    self.head_size = head_size\n",
        "    self.key = nn.Linear(feat_in, head_size, bias=False)\n",
        "    self.query = nn.Linear(feat_in, head_size, bias=False)\n",
        "    self.value = nn.Linear(feat_in, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    B, T, C = X.shape\n",
        "\n",
        "    K = self.key(X)\n",
        "    Q = self.query(X)\n",
        "    V = self.value(X)\n",
        "\n",
        "    sa = K @ Q.transpose(-1, -2) * self.head_size**-0.5\n",
        "    sa = sa.masked_fill(torch.tril(torch.ones(T, T, device=X.device) == 0), float('-inf'))\n",
        "    sa = F.softmax(sa, dim=-1)\n",
        "\n",
        "    return sa @ V"
      ],
      "metadata": {
        "id": "fK3Ku_TDXPg2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHead(nn.Module):\n",
        "  def __init__(self, num_heads, latent_space_dim):\n",
        "    super().__init__()\n",
        "    head_size = latent_space_dim // num_heads\n",
        "    self.num_heads = num_heads\n",
        "    self.heads = nn.ModuleList([\n",
        "        Head(feat_in=latent_space_dim, head_size=head_size) for _ in range(num_heads)\n",
        "        ])\n",
        "    #self.proj = nn.Linear(latent_space_dim, latent_space_dim)\n",
        "\n",
        "  def forward(self, X):\n",
        "    out = torch.cat([h(X) for h in self.heads], dim=-1)\n",
        "    #out = self.proj(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "L4hh6s1YZZaX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, latent_space_dim, hidden_layer_expansion_factor=4):\n",
        "    super().__init__()\n",
        "    self.latent_space_dim = latent_space_dim\n",
        "    self.hidden_layer_expansion_factor = hidden_layer_expansion_factor\n",
        "    self.net = nn.Sequential(\n",
        "            nn.Linear(latent_space_dim, hidden_layer_expansion_factor*latent_space_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_layer_expansion_factor*latent_space_dim, latent_space_dim),\n",
        "        )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)"
      ],
      "metadata": {
        "id": "ESQJ43wUaBVx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, latent_space_dim, num_heads):\n",
        "    super().__init__()\n",
        "    self.self_attention = MultiHead(num_heads=num_heads, latent_space_dim=latent_space_dim)\n",
        "    self.ff = FeedForward(latent_space_dim=latent_space_dim)\n",
        "    self.ln1 = nn.LayerNorm(latent_space_dim)\n",
        "    self.ln2 = nn.LayerNorm(latent_space_dim)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = X + self.self_attention(self.ln1(X))\n",
        "    X = X + self.ff(self.ln2(X))\n",
        "    return X"
      ],
      "metadata": {
        "id": "lD4odrdGb8s6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DanteLM(nn.Module):\n",
        "  def __init__(self, vocab_size, context_window_size, latent_space_dim, num_heads, n_blocks):\n",
        "    super().__init__()\n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    self.context_window_size = context_window_size\n",
        "    self.latent_space_dim = latent_space_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.n_blocks = n_blocks\n",
        "\n",
        "    self.tok_embedding_table = nn.Embedding(vocab_size, latent_space_dim)\n",
        "    self.pos_embedding_table = nn.Embedding(context_window_size, latent_space_dim)\n",
        "    self.blocks = nn.Sequential(\n",
        "        *[Block(latent_space_dim, num_heads) for _ in range(n_blocks)]\n",
        "    )\n",
        "    self.ln_f = nn.LayerNorm(latent_space_dim)\n",
        "    self.lm_head = nn.Linear(latent_space_dim, vocab_size)\n",
        "\n",
        "  def forward(self, idx):\n",
        "    B, T = idx.shape\n",
        "\n",
        "    tok_emb = self.tok_embedding_table(idx) # (B, T, C)\n",
        "    pos_emb = self.pos_embedding_table(torch.arange(T, device=idx.device)) # (T,C)\n",
        "    emb = tok_emb + pos_emb # (B, T, C)\n",
        "    x = self.blocks(emb)\n",
        "    x = self.ln_f(x) # (B,T,C)\n",
        "    logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "    return logits\n",
        "\n",
        "  def compute_loss(self, idx, targets):\n",
        "    logits = self.forward(idx)\n",
        "    B, T, C = logits.shape\n",
        "    logits = logits.view(B*T, C)\n",
        "    targets = targets.view(B*T)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "    return loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens=32):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits = self.forward(idx[:, -self.context_window_size:]) # B, T, C\n",
        "      logits = logits[:, -1, :] # B, C\n",
        "      probs = F.softmax(logits, dim=-1) # B, C\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # idx: (B, T) --> (B, T+1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "S8Fkbok8WqgM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dante = DanteLM(vocab_size=vocab_size, context_window_size=8, latent_space_dim=32, num_heads=4, n_blocks=4)"
      ],
      "metadata": {
        "id": "i7Lx3l6Ge1Um"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability and move model and data\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available. Training on:\", device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available. Training on CPU.\")\n",
        "\n",
        "model = Dante.to(device)  # Move your model to the device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTUbKifFsxbh",
        "outputId": "be1e7f74-cb66-4767-852d-4d066b351724"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available. Training on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(Dante.generate(idx = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=32)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPnRGs5hgDdX",
        "outputId": "8bc7d1d5-5e5c-45a0-ecdd-3a8ea5780375"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ä\n",
            "0r ÈQ“IAöÈE7ù)7jM-z-”5 TéNzZ0I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(Dante.parameters(), lr=1e-3)\n",
        "epochs = 100000\n",
        "for i in range(epochs):\n",
        "\n",
        "  xb, yb = get_batch('loss', batch_size=32, block_size=Dante.context_window_size)\n",
        "  # Move xb and yb to the device and reassign them\n",
        "  xb = xb.to(device)\n",
        "  yb = yb.to(device)\n",
        "\n",
        "  loss = Dante.compute_loss(xb, yb)\n",
        "  if i % 10000 == 0: print(loss.item())\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVn3m2ThmMjM",
        "outputId": "bed20347-d38d-48cf-9a1a-3789a7f14c04"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.700807094573975\n",
            "0.24238070845603943\n",
            "0.2518538236618042\n",
            "0.2248467206954956\n",
            "0.13284353911876678\n",
            "0.2427430897951126\n",
            "0.15608833730220795\n",
            "0.148853600025177\n",
            "0.12976951897144318\n",
            "0.16685450077056885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(Dante.generate(idx = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHCdaIS4mTPs",
        "outputId": "e9835519-8d0c-44cf-f609-305fda1c77d6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            ":«\n",
            "1\n",
            "Sparore corrà già l’etate,\n",
            "non sterno fatta si convenne.\n",
            "A quanto paradise,\n",
            "in venni\n",
            "quei e avvvivile.\n",
            "La s’acccende e accolor incoro a l’unffe,\n",
            "e sì spirava,\n",
            "e al serà uo ragionne si mastui senternagnon si sin tieto\n",
            "l’eplezza:\n",
            "che lüa dre è natura fron ’incosì il giarri si dissinzyezzòa\n",
            "ma intelletto da l’altrucide\n",
            "sume si cielo e cota coma primo al contesi\n",
            "canti intrato sì com’ io conco’nevie: «Ma, com’ io mosse per lo sdov’\n",
            "\n",
            "più ch’i’ vedrai ch’esser l’altro a gncrea, perse non tre rimo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yd9rt930wEBm"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}